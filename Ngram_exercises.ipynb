{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning N-gram Models\n",
    "Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ‚Éùc 2014. All rights reserved. Draft of September 1, 2014.\n",
    "\n",
    "### Ch.4 N-Gram Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta 8/9/2018\n",
    "#reading the chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tiny minicorpus from the chapter - all text as 1 record\n",
    "#$actodo handle separators later\n",
    "minicorpus = [\"<s> I am Sam </s> <s> Sam I am </s> <s> I do not like green eggs and ham </s>\"]\n",
    "\n",
    "#not minicorpus = [\"<s> I am Sam </s>\",  \"<s> Sam I am </s>\", \"<s> I do not like green eggs and ham </s>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful regex for this vocab - unigrams with index\n",
      "{'<s>': 1, 'i': 8, 'am': 2, 'sam': 11, '</s>': 0, 'do': 4, 'not': 10, 'like': 9, 'green': 6, 'eggs': 5, 'and': 3, 'ham': 7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'i',\n",
       " 'am',\n",
       " 'sam',\n",
       " '</s>',\n",
       " 'do',\n",
       " 'not',\n",
       " 'like',\n",
       " 'green',\n",
       " 'eggs',\n",
       " 'and',\n",
       " 'ham']"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get frequency counts\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)[\\<[\\/]*]?\\b\\w+\\b[\\>*]?', ngram_range=(1, 1))\n",
    "#print(type(vectorizer))\n",
    "print('Successful regex for this vocab - unigrams with index')\n",
    "\n",
    "vectorizer.fit(minicorpus)\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "unigrams = list(vectorizer.vocabulary_)\n",
    "unigrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue with Bigrams\n",
    "Building unigram x unigram matrix results in bigram probabilities.  So need to generate frequency counts for bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM type  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Successful vocab - with bigrams:  28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " '</s> <s>',\n",
       " '<s>',\n",
       " '<s> i',\n",
       " '<s> sam',\n",
       " 'am',\n",
       " 'am </s>',\n",
       " 'am sam',\n",
       " 'and',\n",
       " 'and ham',\n",
       " 'do',\n",
       " 'do not',\n",
       " 'eggs',\n",
       " 'eggs and',\n",
       " 'green',\n",
       " 'green eggs',\n",
       " 'ham',\n",
       " 'ham </s>',\n",
       " 'i',\n",
       " 'i am',\n",
       " 'i do',\n",
       " 'like',\n",
       " 'like green',\n",
       " 'not',\n",
       " 'not like',\n",
       " 'sam',\n",
       " 'sam </s>',\n",
       " 'sam i']"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need unigrams and bigrams \n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)[\\<[\\/]*]?\\b\\w+\\b[\\>*]?', ngram_range=(1, 2))\n",
    "#dtm with 1 document\n",
    "dtm = vectorizer.fit_transform(minicorpus) #class 'scipy.sparse.csr.csr_matrix'\n",
    "print ('DTM type ', type(dtm))\n",
    "\n",
    "vocab = vectorizer.get_feature_names() #class list\n",
    "vocab_total=len(vocab)\n",
    "print('Successful vocab - with bigrams: ', vocab_total)\n",
    "\n",
    "vocab #class list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x28 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 28 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM type  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Query dtm: how many times an n-gram occurs in the text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query dtm - only works with 1 row;\n",
    "#if multiple rows, there's no instance of '</s> <s>'\n",
    "print ('DTM type ', type(dtm))\n",
    "ngram_value = '</s> <s>'\n",
    "#ngram_value = 'am sam'\n",
    "ngram_idx = list(vocab).index(ngram_value)\n",
    "print ('Query dtm: how many times an n-gram occurs in the text')\n",
    "dtm[0,ngram_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From sparse matrix into NumPy array  \n",
    "NumPy arrays supports a greater variety of operations than a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM type before:  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "DTM type after <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1,\n",
       "        1, 1, 1, 2, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert from current format, sparse matrix, into a normal numpy array \n",
    "print ('DTM type before: ', type(dtm))\n",
    "dtm = dtm.toarray()\n",
    "print ('DTM type after', type(dtm))\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['</s>', '</s> <s>', '<s>', '<s> i', '<s> sam', 'am', 'am </s>',\n",
       "       'am sam', 'and', 'and ham', 'do', 'do not', 'eggs', 'eggs and',\n",
       "       'green', 'green eggs', 'ham', 'ham </s>', 'i', 'i am', 'i do',\n",
       "       'like', 'like green', 'not', 'not like', 'sam', 'sam </s>',\n",
       "       'sam i'], dtype='<U10')"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert python list storing vocab into numpy array\n",
    "vocab = np.array(vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query dtm\n",
    "ngram_idx = list(vocab).index(ngram_value)\n",
    "dtm[0,ngram_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using NumPy indexing is more natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm[0,vocab == ngram_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print frequency counts (aka dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>&lt;/s&gt; &lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt; i</th>\n",
       "      <th>&lt;s&gt; sam</th>\n",
       "      <th>am</th>\n",
       "      <th>am &lt;/s&gt;</th>\n",
       "      <th>am sam</th>\n",
       "      <th>and</th>\n",
       "      <th>and ham</th>\n",
       "      <th>...</th>\n",
       "      <th>i</th>\n",
       "      <th>i am</th>\n",
       "      <th>i do</th>\n",
       "      <th>like</th>\n",
       "      <th>like green</th>\n",
       "      <th>not</th>\n",
       "      <th>not like</th>\n",
       "      <th>sam</th>\n",
       "      <th>sam &lt;/s&gt;</th>\n",
       "      <th>sam i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   </s>  </s> <s>  <s>  <s> i  <s> sam  am  am </s>  am sam  and  and ham  \\\n",
       "0     3         2    3      2        1   2        1       1    1        1   \n",
       "\n",
       "   ...    i  i am  i do  like  like green  not  not like  sam  sam </s>  sam i  \n",
       "0  ...    3     2     1     1           1    1         1    2         1      1  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print dtm frequency counts\n",
    "df = pd.DataFrame(dtm,columns = vocab)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some bigram probabilities from this corpus\n",
    "Didn't think I could at this point.  Thought I had to build unigram to bigram matrix first.  \n",
    "\n",
    "Wrong.  I have everything at this point.  Probably not efficient, but sufficient.  Worry about efficiency after figure out stats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(I|<s>) = .67  \n",
    "#P(Sam|<s>) = .33 \n",
    "#P(am|I) = .67 \n",
    "#P(</s>|Sam) = 0.5 \n",
    "#P(Sam|am)  = .5 \n",
    "#P(do|I) = .33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate some bigram probabilities - \n",
    "#P(I|<s>) = .67 \n",
    "\n",
    "n_gram_of = '<s> i'\n",
    "n_gram_given = '<s>'\n",
    "p_bigram = dtm[0,list(vocab).index(n_gram_of)] / dtm[0,list(vocab).index(n_gram_given)]\n",
    "\n",
    "p_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(Sam|<s>) = .33 \n",
    "\n",
    "n_gram_of = '<s> sam'\n",
    "n_gram_given = '<s>'\n",
    "p_bigram = dtm[0,list(vocab).index(n_gram_of)] / dtm[0,list(vocab).index(n_gram_given)]\n",
    "\n",
    "p_bigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(am|I) = .67 \n",
    "\n",
    "n_gram_of = 'i am'\n",
    "n_gram_given = 'i'\n",
    "p_bigram = dtm[0,list(vocab).index(n_gram_of)] / dtm[0,list(vocab).index(n_gram_given)]\n",
    "\n",
    "p_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(</s>|Sam) = .5 \n",
    "n_gram_of = 'sam </s>'\n",
    "n_gram_given = 'sam'\n",
    "p_bigram = dtm[0,list(vocab).index(n_gram_of)] / dtm[0,list(vocab).index(n_gram_given)]\n",
    "\n",
    "p_bigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(Sam|am)  = .5 \n",
    "\n",
    "n_gram_of = 'am sam'\n",
    "n_gram_given = 'am'\n",
    "p_bigram = dtm[0,list(vocab).index(n_gram_of)] / dtm[0,list(vocab).index(n_gram_given)]\n",
    "\n",
    "p_bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(do|I) = .33\n",
    "\n",
    "n_gram_of = 'i do'\n",
    "n_gram_given = 'i'\n",
    "p_bigram = dtm[0,list(vocab).index(n_gram_of)] / dtm[0,list(vocab).index(n_gram_given)]\n",
    "\n",
    "p_bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(not|do)  = 1 \n",
    "\n",
    "n_gram_of = 'do not'\n",
    "n_gram_given = 'do'\n",
    "p_bigram = dtm[0,list(vocab).index(n_gram_of)] / dtm[0,list(vocab).index(n_gram_given)]\n",
    "\n",
    "p_bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(<s>|</s>)  = .67\n",
    "\n",
    "n_gram_of = '</s> <s>'\n",
    "n_gram_given = '</s>'\n",
    "p_bigram = dtm[0,list(vocab).index(n_gram_of)] / dtm[0,list(vocab).index(n_gram_given)]\n",
    "\n",
    "p_bigram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build bigram probability matrix\n",
    "manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'i',\n",
       " 'am',\n",
       " 'sam',\n",
       " '</s>',\n",
       " 'do',\n",
       " 'not',\n",
       " 'like',\n",
       " 'green',\n",
       " 'eggs',\n",
       " 'and',\n",
       " 'ham']"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print unigrams for reference\n",
    "unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_freq_mx = np.zeros(shape = (len(unigrams),len(unigrams)))\n",
    "bigram_freq_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> <s>\n",
      "none\n",
      "<s> i\n",
      "0.6666666666666666\n",
      "<s> am\n",
      "none\n",
      "<s> sam\n",
      "0.3333333333333333\n",
      "<s> </s>\n",
      "none\n",
      "<s> do\n",
      "none\n",
      "<s> not\n",
      "none\n",
      "<s> like\n",
      "none\n",
      "<s> green\n",
      "none\n",
      "<s> eggs\n",
      "none\n",
      "<s> and\n",
      "none\n",
      "<s> ham\n",
      "none\n",
      "i <s>\n",
      "none\n",
      "i i\n",
      "none\n",
      "i am\n",
      "0.6666666666666666\n",
      "i sam\n",
      "none\n",
      "i </s>\n",
      "none\n",
      "i do\n",
      "0.3333333333333333\n",
      "i not\n",
      "none\n",
      "i like\n",
      "none\n",
      "i green\n",
      "none\n",
      "i eggs\n",
      "none\n",
      "i and\n",
      "none\n",
      "i ham\n",
      "none\n",
      "am <s>\n",
      "none\n",
      "am i\n",
      "none\n",
      "am am\n",
      "none\n",
      "am sam\n",
      "0.5\n",
      "am </s>\n",
      "0.5\n",
      "am do\n",
      "none\n",
      "am not\n",
      "none\n",
      "am like\n",
      "none\n",
      "am green\n",
      "none\n",
      "am eggs\n",
      "none\n",
      "am and\n",
      "none\n",
      "am ham\n",
      "none\n",
      "sam <s>\n",
      "none\n",
      "sam i\n",
      "0.5\n",
      "sam am\n",
      "none\n",
      "sam sam\n",
      "none\n",
      "sam </s>\n",
      "0.5\n",
      "sam do\n",
      "none\n",
      "sam not\n",
      "none\n",
      "sam like\n",
      "none\n",
      "sam green\n",
      "none\n",
      "sam eggs\n",
      "none\n",
      "sam and\n",
      "none\n",
      "sam ham\n",
      "none\n",
      "</s> <s>\n",
      "0.6666666666666666\n",
      "</s> i\n",
      "none\n",
      "</s> am\n",
      "none\n",
      "</s> sam\n",
      "none\n",
      "</s> </s>\n",
      "none\n",
      "</s> do\n",
      "none\n",
      "</s> not\n",
      "none\n",
      "</s> like\n",
      "none\n",
      "</s> green\n",
      "none\n",
      "</s> eggs\n",
      "none\n",
      "</s> and\n",
      "none\n",
      "</s> ham\n",
      "none\n",
      "do <s>\n",
      "none\n",
      "do i\n",
      "none\n",
      "do am\n",
      "none\n",
      "do sam\n",
      "none\n",
      "do </s>\n",
      "none\n",
      "do do\n",
      "none\n",
      "do not\n",
      "1.0\n",
      "do like\n",
      "none\n",
      "do green\n",
      "none\n",
      "do eggs\n",
      "none\n",
      "do and\n",
      "none\n",
      "do ham\n",
      "none\n",
      "not <s>\n",
      "none\n",
      "not i\n",
      "none\n",
      "not am\n",
      "none\n",
      "not sam\n",
      "none\n",
      "not </s>\n",
      "none\n",
      "not do\n",
      "none\n",
      "not not\n",
      "none\n",
      "not like\n",
      "1.0\n",
      "not green\n",
      "none\n",
      "not eggs\n",
      "none\n",
      "not and\n",
      "none\n",
      "not ham\n",
      "none\n",
      "like <s>\n",
      "none\n",
      "like i\n",
      "none\n",
      "like am\n",
      "none\n",
      "like sam\n",
      "none\n",
      "like </s>\n",
      "none\n",
      "like do\n",
      "none\n",
      "like not\n",
      "none\n",
      "like like\n",
      "none\n",
      "like green\n",
      "1.0\n",
      "like eggs\n",
      "none\n",
      "like and\n",
      "none\n",
      "like ham\n",
      "none\n",
      "green <s>\n",
      "none\n",
      "green i\n",
      "none\n",
      "green am\n",
      "none\n",
      "green sam\n",
      "none\n",
      "green </s>\n",
      "none\n",
      "green do\n",
      "none\n",
      "green not\n",
      "none\n",
      "green like\n",
      "none\n",
      "green green\n",
      "none\n",
      "green eggs\n",
      "1.0\n",
      "green and\n",
      "none\n",
      "green ham\n",
      "none\n",
      "eggs <s>\n",
      "none\n",
      "eggs i\n",
      "none\n",
      "eggs am\n",
      "none\n",
      "eggs sam\n",
      "none\n",
      "eggs </s>\n",
      "none\n",
      "eggs do\n",
      "none\n",
      "eggs not\n",
      "none\n",
      "eggs like\n",
      "none\n",
      "eggs green\n",
      "none\n",
      "eggs eggs\n",
      "none\n",
      "eggs and\n",
      "1.0\n",
      "eggs ham\n",
      "none\n",
      "and <s>\n",
      "none\n",
      "and i\n",
      "none\n",
      "and am\n",
      "none\n",
      "and sam\n",
      "none\n",
      "and </s>\n",
      "none\n",
      "and do\n",
      "none\n",
      "and not\n",
      "none\n",
      "and like\n",
      "none\n",
      "and green\n",
      "none\n",
      "and eggs\n",
      "none\n",
      "and and\n",
      "none\n",
      "and ham\n",
      "1.0\n",
      "ham <s>\n",
      "none\n",
      "ham i\n",
      "none\n",
      "ham am\n",
      "none\n",
      "ham sam\n",
      "none\n",
      "ham </s>\n",
      "1.0\n",
      "ham do\n",
      "none\n",
      "ham not\n",
      "none\n",
      "ham like\n",
      "none\n",
      "ham green\n",
      "none\n",
      "ham eggs\n",
      "none\n",
      "ham and\n",
      "none\n",
      "ham ham\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "#populate bigram matrix - manually\n",
    "#i rows, j columns\n",
    "\n",
    "cnt_i = 0\n",
    "#loop over rows\n",
    "for i in unigrams:\n",
    "    \n",
    "    cnt_j = 0    \n",
    "    #loop over columns\n",
    "    for j in unigrams:\n",
    "        bigram = i+' '+j\n",
    "        print (bigram)\n",
    "        \n",
    "        try:\n",
    "            prob = dtm[0,list(vocab).index(bigram)] / dtm[0,list(vocab).index(i)]\n",
    "            print (prob)\n",
    "            bigram_freq_mx[cnt_i,cnt_j]=round(prob, 2)\n",
    "            \n",
    "        except ValueError:\n",
    "            print('none')\n",
    "        finally:\n",
    "            cnt_j+=1\n",
    "            #print('----', j, cnt_j)\n",
    "    \n",
    "    cnt_i+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.67, 0.  , 0.33, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.  , 0.67, 0.  , 0.  , 0.33, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.5 , 0.5 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.5 , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.67, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "        0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        1.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  ]])"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_freq_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### findings\n",
    "At run time will only be interested in one row of the matrix, therefore no need to pre-calculate the entire matrix beforehand.  \n",
    "Next step: compute one row of the matrix - still manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07692308 0.05128205 0.07692308 0.05128205 0.02564103 0.05128205\n",
      "  0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      "  0.02564103 0.02564103 0.02564103 0.02564103 0.02564103 0.02564103\n",
      "  0.07692308 0.05128205 0.02564103 0.02564103 0.02564103 0.02564103\n",
      "  0.02564103 0.05128205 0.02564103 0.02564103]]\n"
     ]
    }
   ],
   "source": [
    "#normalize frequency counts\n",
    "dtm_normalized = dtm/dtm.sum()\n",
    "print(dtm_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['</s>' '</s> <s>' '<s>' '<s> i' '<s> sam' 'am' 'am </s>' 'am sam' 'and'\n",
      " 'and ham' 'do' 'do not' 'eggs' 'eggs and' 'green' 'green eggs' 'ham'\n",
      " 'ham </s>' 'i' 'i am' 'i do' 'like' 'like green' 'not' 'not like' 'sam'\n",
      " 'sam </s>' 'sam i']\n",
      "Found bigrams with \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 7]"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute prob of all bigrams \n",
    "start_token = 'am'\n",
    "#Q: given 'am', what are all bigrams and their probabilites?\n",
    "#P(Sam|am)  = .5 \n",
    "\n",
    "#work with all vocab\n",
    "print(vocab)\n",
    "#--check if vocab contains a unigram token 'am' and if yes, where\n",
    "start_token in vocab #True\n",
    "#vocab.index(start_token)\n",
    "\n",
    "#--check if vocab contains bigram token(s) starting with 'am' \n",
    "#for term in vocab:\n",
    "#    print (term.startswith(start_token))\n",
    "\n",
    "#--check if vocab contains tokens startubg with 'am' and if yes, where\n",
    "#no loop, check if vocab contains bigram token(s) starting with 'am' \n",
    "#refer to https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.char.html\n",
    "#https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.core.defchararray.startswith.html#numpy.core.defchararray.startswith\n",
    "np.core.defchararray.startswith(vocab, start_token) #returns boolean array\n",
    "\n",
    "print('Found bigrams with ')\n",
    "bigrams_idx = np.where(np.core.defchararray.startswith(vocab, start_token + ' '))\n",
    "bigrams_idx[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams and their probabilities: \n",
      "['am </s>' 'am sam']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03571428571428571, 0.03571428571428571]"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calc prob of relevant tokens\n",
    "#vocab[np.where(np.core.defchararray.startswith(vocab, start_token + ' '))]\n",
    "np.where(np.core.defchararray.startswith(vocab, start_token + ' '),0,-1)\n",
    "dtm[0, bigrams_idx[0].tolist()]\n",
    "bigrams_prob = dtm[0, bigrams_idx[0].tolist()]/vocab_total\n",
    "\n",
    "print(\"Bigrams and their probabilities: \")\n",
    "print(vocab[bigrams_idx])\n",
    "bigrams_prob.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue with Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need unigrams and bigrams \n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)[\\<[\\/]*]?\\b\\w+\\b[\\>*]?', ngram_range=(1, 2))\n",
    "dtm = vectorizer.fit_transform(minicorpus) #class 'scipy.sparse.csr.csr_matrix'\n",
    "print ('DTM type ', type(dtm))\n",
    "\n",
    "vocab = vectorizer.get_feature_names() #class list\n",
    "print('Successful vocab - bigrams')\n",
    "\n",
    "vocab #class list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xtra\n",
    "\n",
    "#### Word Counts with CountVectorizer\n",
    "https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\"]\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
